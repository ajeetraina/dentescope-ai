# ğŸ¦· DenteScope AI - Dental X-ray Tooth Detection

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.9.0-red.svg)
![YOLOv8](https://img.shields.io/badge/YOLOv8-8.3.223-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)

**Production-ready AI system for automated tooth detection in dental panoramic X-rays**

[ğŸš€ Live Demo](https://huggingface.co/spaces/ajeetsraina/dentescope-ai) â€¢ [ğŸ“– Blog Post](BLOG_POST.md) â€¢ [ğŸ’» GitHub](https://github.com/ajeetraina/dentescope-ai-complete)

<img src="results/width_analysis/tooth_width_analysis_charts.png" alt="Analysis Results" width="800"/>

</div>

---

## ğŸŒ Live Demo

**[Try DenteScope AI Now! â†’](https://huggingface.co/spaces/ajeetsraina/dentescope-ai)**

Upload a dental panoramic X-ray and get instant:
- âœ… Tooth detection with 99.5% accuracy
- âœ… Width & height measurements in pixels and mm
- âœ… Confidence scores for each detection
- âœ… Visual annotations on your image

*No installation required - runs entirely in your browser!*

---

## ğŸ¯ Overview

DenteScope AI is a state-of-the-art deep learning system for automated tooth detection in dental panoramic X-rays. Built with YOLOv8 and trained on real dental imagery, it achieves production-ready performance for clinical deployment.

### Key Features

- ğŸ¯ **99.5% mAP50 Accuracy** - Professional-grade detection
- ğŸš€ **Fast Inference** - ~570ms per image
- ğŸ“ **Automated Measurements** - Width and height in pixels/mm
- ğŸ”„ **Iterative Training** - Self-improving annotation pipeline
- ğŸ“¦ **Dockerized** - Easy deployment on any platform
- ğŸŒ **Web Interface** - Live demo on Hugging Face Spaces

---

## ğŸ“Š Performance

### Production Model (V2) - YOLOv8s

| Metric | Score | Status |
|--------|-------|--------|
| **mAP50** | **99.5%** | ğŸŸ¢ Excellent |
| **mAP50-95** | **98.5%** | ğŸŸ¢ Excellent |
| **Precision** | **99.6%** | ğŸŸ¢ Excellent |
| **Recall** | **100%** | ğŸŸ¢ Perfect |
| **Training Time** | 2.6 hours | âš¡ Efficient |
| **Model Size** | 22.5 MB | ğŸ’¾ Compact |

### Training Evolution
```
V1 Baseline:    mAP50 49.9% (auto-annotated dataset)
      â†“
Re-annotation:  Using trained V1 model
      â†“
V2 Production:  mAP50 99.5% (refined annotations) âœ¨
```

**Key Achievement:** +99.2% improvement through iterative training!

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- Docker (optional, recommended)
- NVIDIA GPU (optional, but faster)

### Installation
```bash
# Clone repository
git clone https://github.com/ajeetraina/dentescope-ai-complete.git
cd dentescope-ai-complete

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install ultralytics opencv-python pillow pyyaml matplotlib pandas openpyxl
```

### Basic Usage
```python
from ultralytics import YOLO

# Load production model
model = YOLO('runs/train/tooth_detection7/weights/best.pt')

# Predict on image
results = model.predict('dental_xray.jpg', conf=0.25, save=True)

# Get measurements
for r in results:
    for box in r.boxes:
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        width_px = x2 - x1
        width_mm = width_px * 0.1  # Calibration factor
        conf = box.conf[0].item()
        
        print(f"Tooth detected:")
        print(f"  Width: {width_px:.1f}px ({width_mm:.1f}mm)")
        print(f"  Confidence: {conf:.1%}")
```

---

## ğŸ³ Docker Deployment

### Run with Docker
```bash
# Pull container
docker pull nvcr.io/nvidia/cuda:13.0.0-devel-ubuntu24.04

# Run training environment
docker run -it --rm \
  --runtime nvidia \
  --gpus all \
  -v $(pwd):/workspace \
  -w /workspace \
  nvcr.io/nvidia/cuda:13.0.0-devel-ubuntu24.04 \
  bash

# Inside container
apt-get update && apt-get install -y python3 python3-pip libgl1
pip3 install ultralytics --break-system-packages

# Train model
python3 train_tooth_model.py --dataset ./data/v2_dataset_fixed
```

---

## ğŸ“ Training Pipeline

### Step 1: Data Preparation
```bash
# Organize your dental X-rays
python3 prepare_data.py --source data/raw --output data/train
```

### Step 2: Auto-Annotation (Bootstrap)
```bash
# Generate initial annotations using pretrained YOLOv8
python3 auto_annotate_all.py \
  --images data/train/images \
  --output data/train/labels
```

### Step 3: V1 Baseline Training
```bash
# Train baseline model
python3 train_tooth_model.py \
  --dataset ./data/train \
  --model-size n \
  --epochs 100
```

### Step 4: Re-Annotation
```bash
# Use trained V1 model to generate better annotations
python3 reannotate_with_model.py \
  --model runs/train/tooth_detection5/weights/best.pt \
  --images data/raw \
  --output data/reannotated/labels
```

### Step 5: V2 Production Training
```bash
# Train production model with improved annotations
python3 train_tooth_model.py \
  --dataset ./data/v2_dataset_fixed \
  --model-size s \
  --epochs 100
```

---

## ğŸ“ Width Analysis

### Analyze Tooth Measurements
```bash
# Run comprehensive width analysis
python3 view_tooth_width.py \
  --model runs/train/tooth_detection7/weights/best.pt \
  --images data/v2_dataset_fixed/images/val \
  --output results/width_analysis

# Generate statistics and visualizations
python3 analyze_tooth_widths.py
```

### Analysis Results

- **15 patients analyzed** with 100% detection rate
- **Mean width:** 165.7mm (Â±0.5mm)
- **Confidence:** 93.3% average
- Outputs: Annotated images, CSV report, Excel file, 4-panel charts

---

## ğŸ“ Project Structure
```
dentescope-ai-complete/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original 73 dental X-rays
â”‚   â”œâ”€â”€ train/                  # Training data (V1)
â”‚   â”œâ”€â”€ valid/                  # Validation data
â”‚   â”œâ”€â”€ reannotated/            # Re-annotated dataset
â”‚   â””â”€â”€ v2_dataset_fixed/       # Final V2 training dataset
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ tooth_detection5/   # V1 model (mAP50: 49.9%)
â”‚       â””â”€â”€ tooth_detection7/   # V2 model (mAP50: 99.5%) â­
â”œâ”€â”€ results/
â”‚   â””â”€â”€ width_analysis/         # Width measurements & charts
â”œâ”€â”€ hf-deploy/                  # Hugging Face deployment files
â”‚   â”œâ”€â”€ app.py                  # Gradio web interface
â”‚   â”œâ”€â”€ best.pt                 # Production model
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ train_tooth_model.py        # Training script
â”œâ”€â”€ view_tooth_width.py         # Width analysis tool
â”œâ”€â”€ analyze_tooth_widths.py     # Comprehensive analysis
â”œâ”€â”€ BLOG_POST.md               # Complete guide
â””â”€â”€ README.md                   # This file
```

---

## ğŸ’» Tech Stack

- **Framework:** [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) - State-of-the-art object detection
- **Deep Learning:** PyTorch 2.9.0
- **Hardware:** NVIDIA Jetson Thor (ARM64)
- **Container:** Docker with CUDA 13.0
- **Deployment:** Hugging Face Spaces with Gradio
- **Language:** Python 3.12

---

## ğŸ¯ Use Cases

### Clinical Applications
- ğŸ¥ Automated screening in dental clinics
- ğŸ“Š Batch processing of patient X-rays
- ğŸ“ Dimensional analysis for orthodontics
- ğŸ“ Training tool for dental students

### Research Applications
- ğŸ”¬ Dental morphology studies
- ğŸ“ˆ Population-level statistics
- ğŸ§ª Treatment outcome analysis
- ğŸ“ Automated annotation for datasets

---

## ğŸ“– Documentation

- **[Complete Blog Post](BLOG_POST.md)** - Full step-by-step guide with code
- **[Live Demo](https://huggingface.co/spaces/ajeetsraina/dentescope-ai)** - Try it now!

### External Resources

- [Ultralytics YOLOv8 Docs](https://docs.ultralytics.com/)
- [NVIDIA Jetson Thor](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-thor/)
- [Hugging Face Spaces](https://huggingface.co/docs/hub/spaces)
- [Docker Documentation](https://docs.docker.com/)

---







